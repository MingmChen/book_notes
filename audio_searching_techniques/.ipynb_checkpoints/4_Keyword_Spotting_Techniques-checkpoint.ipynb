{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Keyword Spotting Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keyword spotting(KWS) refers to the spotting and retrival of predefined keywords from audio database.**\n",
    "\n",
    "### 1. Techniques for Keyword Spotting\n",
    "Different keyword spotting techniques are discussed below.\n",
    "\n",
    "#### a) Template-Concatenation Model\n",
    "> **模板匹配**：\n",
    "![](images/4_1.png)\n",
    "> **缺点**: \n",
    "    - 计算量大\n",
    "    - FA（False Alarm）高\n",
    "\n",
    "> **改进**：\n",
    "    - 增加背景模型，吸收FA\n",
    "![](images/4_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Hidden Markov Models(HMM)\n",
    "> * Better performance than the template-based systems.\n",
    "* HMM对keyword 和 Filler 进行建模，Filler 可以采用以下形式\n",
    "    1. Acoustic word models\n",
    "    2. Acoustic sub-word models(Triphone/Monophone/syllable models)\n",
    "    3. Clustered models( clustered Gaussian)\n",
    "    4. Vocabulary-independent models\n",
    "* 可以处理任意多的Keyword\n",
    "* **缺点**：\n",
    "    1. OOV无法处理\n",
    "    2. Viterbi 解码，计算量偏大\n",
    "    3. 测试集若与声学模型训练集失配，性能会有比较大的下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) LVCSR-based Techniques\n",
    "> **先将audio识别成文本，然后从文本中查找Keyword**\n",
    "* Very accurate for well-resourced languages\n",
    "* Main limitation: Need large amount of trancscribed data and inability ro handle OOV words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Predictive Neural Model\n",
    "> **实现**    \n",
    "* 训练多个MLP predictor(每个MLP相当于一个encoder，训练使其输出 \\\\(\\hat{a_t}\\\\)尽可能逼近当前输入 \\\\(a_t\\\\), **prediction residual: **\\\\(||\\hat{a_t}-a_t||\\\\) )   \n",
    "![](images/4_3.png)\n",
    "* 对keyword按一定的单元大小(word, syllable, phoneme)进行建模，每个节点对应一个MLP\n",
    "![](images/4_4.png)\n",
    "* 识别时，计算每个MLP的欧式距离残差，DP算法求得最小的残差和及对应的解码路径\n",
    "![](images/4_5.png)\n",
    "* Keyword is detected if the accumulated prediction residual has a value lesser than a threshold value.\n",
    "\n",
    "> **优点**:\n",
    "    1. Simple structure\n",
    "    2. Easy to train\n",
    "    3. Training Flexibility is possible. Word/syllable/phone level training can be done.\n",
    "    4. No need to train non-keyword model\n",
    "    5. Non-keyword is rejected based on the accumulated prediction residual score\n",
    "    \n",
    "> **Reference**:  \n",
    "*[1] Iso K, Watanabe T. Speaker-independent word recognition using a neural prediction model[M]//Readings in speech recognition. 1990: 443-446.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Phone Lattice Alignment\n",
    "> * 构建Phoneme lattice，DP 检索 keyword\n",
    "* much faster than HMM-based approach\n",
    "* no concept of vocabulary/OOV words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f) Modefied Minimum Edit Distance Measure\n",
    "![](images/4_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g) Segmental Models\n",
    "![](images/4_7.png)\n",
    "> **实现: **   \n",
    "* 根据频谱特性对语音数据进行分段\n",
    "* 对分段的语音进行聚类，用 GMM 对聚类后的数据进行建模，即（SGMM, Segmental Gaussian Mixtrue Model）\n",
    "* 训练时，同样采用 SGMM 对数据进行建模，得到JMM(Joint Multigram Model）\n",
    "* DP 搜索，得到结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### h) Multilayer Perceptron(MLP)\n",
    "![](images/4_8.png)\n",
    "> * **Language-Independent**\n",
    "* KL divergence performs better than dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Deep Neural Networks\n",
    "![](images/4_9.png)\n",
    "> **Reference:**   \n",
    "*[1] Chen G, Parada C, Heigold G. Small-footprint keyword spotting using deep neural networks[C]//ICASSP. 2014, 14: 4087-4091.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### j) Spectrographic Seam Patterns\n",
    "![](images/4_10.png)\n",
    "> * a sliding window is used for feature extraction and classfication\n",
    "* extract seam-Hough feature from the speech signal\n",
    "* smoothing\n",
    "* SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k) Spectro-Temporal Patch Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Utterance Verification\n",
    "* For **long Keywords**, Most of the systems perform well.\n",
    "* For **shorter Keywords**, the performance will degrade because of the **higher false alarm rate**.\n",
    "\n",
    "Hence, a second stage is preferred to verify the utterance identified by the first stage, **an isolated keyword verification system helps to reduce the false alarm**.\n",
    "![](images/4_11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Confidence Measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Hybrid Neural Network/HMM Approach\n",
    "![](images/4_12.png)\n",
    "> **基本思想**：\n",
    "* 从 HMM 中得到 keyword， anti-word, Filler  的似然度 \\\\(L(0|K_w), L(O|A_w), L(O|Fil)\\\\)\n",
    "* 从 HMM 中得到 duration\n",
    "* 将上述特征作为**后置 Neural network classifier** 的输入，使用更多的特征，提高分类的准确度。\n",
    "\n",
    "> **Reference:**   \n",
    "*[1] Ou J, Chen K, Wang X, et al. Utterance verification of short keywords using hybrid neural-network/HMM approach[C]//Info-tech and Info-net, 2001. Proceedings. ICII 2001-Beijing. 2001 International Conferences on. IEEE, 2001, 2: 671-676.*   \n",
    "*[2] Wu M, Panchapagesan S, Sun M, et al. Monophone-Based Background Modeling for Two-Stage On-Device Wake Word Detection[C]//2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018: 5494-5498.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Cohort Word-Level verification\n",
    ">**Cohort keywords are words that have similar pronunciation to the target keywords**  \n",
    "\n",
    "> **基本思想**：    \n",
    "* 添加发音相似的anti-word，用于吸收一些发音相似的FA\n",
    "* 计算anti-word 和 keyword 之间的似然度之差\n",
    "\n",
    ">$$\n",
    "LLR = log P(O|{\\lambda}_{kw}) - \\frac{1}{B} \\sum_{i=1}^{B} log P(O|{\\lambda}_{q_i}) \n",
    "$$\n",
    "**or**\n",
    "$$\n",
    "LLR = log P(O|{\\lambda}_{kw}) - \\frac{1}{B} \\max_{i=1}^{B} log P(O|{\\lambda}_{q_i}) \n",
    "$$\n",
    "where \\\\(O\\\\) is the observation sequence, \\\\({\\lambda}_{kw}\\\\) is the keyword model, and \\\\(B\\\\) is the number of cohort words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
