{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Features, Representations and Matching Techniques for Audio Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different primary features and representations popular for for audio searching are discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Primary Features\n",
    "* **MFCC**(Mel-Frequency Cepstral Coefficents)\n",
    "![](images/3_1.png)\n",
    "* **FBCC**(Fourier-Bessel Cepstral Coefficents)\n",
    "![](images/3_2.png)\n",
    "* **LPCC**(Linear Prediction Ceptral Coefficents)\n",
    "* **PLP**(Perceptual Linear Prediction)\n",
    "![](images/3_3.png)\n",
    "* **FDLP**(Frequency Domain Linear Prediction Cepstral Coefficients)\n",
    "![](images/3_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Representation for Audio Search\n",
    "\n",
    "#### a)Seam Patterns\n",
    "\n",
    "> 把语谱图当做图像处理，动态规划查找能量最大的频谱路径。（Seam represents the path of maximum spectral \"whiteness\" across frequency in spectrogram）\n",
    "\n",
    "> * For similar type of sound, seams will be least variant/almost invariant.\n",
    "> * For different sounds, seams will be different.\n",
    "\n",
    "#### b) Patches\n",
    "> * extracted from the Mel-spectrogram\n",
    "\n",
    "#### c) Posteriorgrams\n",
    "> * **Gaussian posteriorgrams** and **phonetic posteriorgrams** are the main posteriorgram representations.\n",
    "* Primary features such as MFCC/FBCC are used for obtaining posteriorgrams.\n",
    "* Phonetic posteriorgram is a time vs class matrix, representing the posterior probability of each phone class for each time frame.\n",
    "![](images/3_5.png)\n",
    "\n",
    "#### d) Lattice of Segment Labels\n",
    "> * Word Lattice\n",
    "    1. inability to detect OOV words\n",
    "    2. recognition errors\n",
    "    3. slow decoding of LVCSR\n",
    "    4. need of large amount of data to train\n",
    "    5. increase in the computational cost\n",
    "    6. underfitting for another domain\n",
    "* Phone Lattice\n",
    "    1. it can avoid OOV problems\n",
    "    2. no need for lexicon or pronunciation dictionary\n",
    "    3. language independent\n",
    "    4. reduce the computational demands\n",
    "* Confusion Network\n",
    "\n",
    "#### e) Bag of Acoustic Words and Inverted Indexing\n",
    "> * 借鉴词袋模型的思路\n",
    "* word loop得到一系列的word，得到词频向量\n",
    "* 词频向量用于后续分类\n",
    "![](images/3_6.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Matching Technique: Dynamic Time Warping\n",
    "\n",
    "**A widely used accepted pattern matching algorithm**. Some of the DTW variants are discussed below:\n",
    "\n",
    "#### a) Basic DTW\n",
    "> * **Define:**\n",
    "$$\n",
    "\\begin{align*}\n",
    "D_a(n,m) = d(Q(n), T(m)) + \\min [ & D_a (n-1, m-1),  \\\\\n",
    "                       & D_a(n, m-1)],    \\\\\n",
    "                       & D_a(n-1,m) ]\n",
    "\\end{align*}\n",
    "$$\n",
    "where   \n",
    "\\\\(D_a(n-1, m-1)\\\\): **Match**   \n",
    "\\\\(D_a(n-1, m-1)\\\\): **Insertion**   \n",
    "\\\\(D_a(n-1, m-1)\\\\): **Deletion**   \n",
    "\n",
    "> * **Constrains(解码约束)**\n",
    "![](images/3_8.png)\n",
    "\n",
    "> * **Global constrains**:\n",
    "语速虽然是可变的，但它的变化应该在一定的范围内，因此可以对DTW的路径增加全局约束，**降低计算复杂度**\n",
    "![](images/3_7.png)\n",
    "\n",
    "> * **Local constrains**   \n",
    "多个路径加权得到当前节点的cost。\n",
    "    1. Itakura arc:\n",
    "$$\n",
    "    S(i,j)=d(i,j) + \\min({\\omega}_1S(i,j-1) + {\\omega}_2S(i-1,j) + {\\omega}_3S(i-2,j-1))\n",
    "$$\n",
    "    2. Needleman-Wunsch arc:\n",
    "$$\n",
    "    S(i,j)=d(i,j) + \\min({\\omega}_1S(i,j-1) + {\\omega}_2S(i-1,j) + {\\omega}_3S(i-1,j-1))\n",
    "$$\n",
    "![](images/3_9.png)\n",
    "\n",
    "#### b) Constrained-Endpoint DTW(CE-DTW)\n",
    "> 1. 匹配的端点固定 \n",
    "2. 性能严重依赖于端点检测的准确性\n",
    "\n",
    "#### c) Unconstrained-Endpoint DTW(UE-DTW)\n",
    "> 1. 克服端点检测不准导致的性能下降\n",
    "2. **端点的取值具有一定的灵活性**（Permits local constraint relaxations up to \"\\\\(x\\\\)\" frames, but only at the start and end locations）\n",
    "3. UELM(Unconstrained-Endpoint Loacl Minimum)，同时track n-best paths，通过剪枝减小搜索空间。\n",
    "![](images/3_10.png)\n",
    "\n",
    "#### d) Modified DTW\n",
    "> **本质上就是加权的DTW**, it is insured that any final path will have equal contribution from each query frame regardless of the total number of test frames absorbed by the path.    \n",
    "**Define：**\n",
    "* Slope factor\n",
    "$$\n",
    "    \\gamma = \\max (n,m)\n",
    "$$\n",
    "* Distance Score if \\\\(m=1\\\\):\n",
    "$$\n",
    "S(q_i \\to q_{i+n}, t_j \\to t_{j+1}) = {\\gamma}^{\\varphi} \\sum_{k=1}^{n} D(q_{i+k}, t_{j+1})\n",
    "$$\n",
    "* Distance Score if \\\\(n=1\\\\):\n",
    "$$\n",
    "S(q_i \\to q_{i+1}, t_j \\to t_{j+m}) = \\frac{{\\gamma}^{\\varphi}}{m} \\sum_{k=1}^{m} D(q_{i+1}, t_{j+k})\n",
    "$$\n",
    "where \\\\(q, t\\\\) are query and test utterance vector.\n",
    "\n",
    "#### e) Segmental DTW\n",
    "> 1. **Object**: The length of test utterance is usually very much greater than query utterance.  \n",
    "2. **Solution**: 对test utterance 加窗，窗和窗之间有一定的重叠。\n",
    "3. **Drawback**: 计算量大\n",
    "![](images/3_11.png)\n",
    "\n",
    "#### f) Modified Segmental DTW\n",
    "> * Segmental Locally Normalized DTW\n",
    "* Memory Efficient Subsequence DTW\n",
    "\n",
    "#### g) Non-segmental DTW\n",
    "> 解决S-DTW中计算量大的矛盾   \n",
    "**实现**：\n",
    "1. a similarity matrix \\\\(S\\\\) of size \\\\(m\\times n\\\\) is computed.\n",
    "2. the query term is likely to start from any point in the test data\n",
    "3. k-best alignment scoring can be get from the similarity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Matching Technique: Minimum Edit Distance(MED)\n",
    "* **What is MED?**\n",
    "    1. MED is defined as the minimum cost of converting one string to the other using the three basic operations(Insertion(I), Substitution(S) and Deletion(D)).\n",
    "    2. The most popular algorithms to find the string distance\n",
    "    3. MED is computed by dynamic programming.\n",
    "* **How to used in audio search:**\n",
    "    1. Convert the audio file to corresponding text messages\n",
    "    2. Calculate the minimum MED between two strings(query and test sequences)\n",
    "\n",
    "* **Conventional MED**\n",
    "> Consider two strings \\\\(U\\\\) and \\\\(V\\\\) with lengths \\\\(p\\\\) and \\\\(q\\\\) respectively, the distance matrix \\\\(M(0,...,p)(0,...,q)\\\\) for \\\\(U\\\\) and \\\\(V\\\\) can be calculated as:\n",
    "![](images/3_12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
